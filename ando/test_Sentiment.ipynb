{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOj3e+MxQ/w4/cbYp63fVU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rnlcksgdkd/Project_AI/blob/ando/ando/test_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1SoNDUnCXfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5158f752-831c-41a8-e37a-3a3a0051b811"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "!pip install konlpy\n",
        "from konlpy.tag import Okt\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaQwe_pPC5UV",
        "outputId": "87525cef-7a1f-44fa-fd77-a952457cdca8"
      },
      "source": [
        "!git clone https://github.com/Rnlcksgdkd/Project_AI"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Project_AI'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 343 (delta 33), reused 23 (delta 21), pack-reused 298\u001b[K\n",
            "Receiving objects: 100% (343/343), 123.02 MiB | 28.00 MiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctP_xBCGC6p1",
        "outputId": "ad51687a-8761-4b69-d3e2-0f188fa45d5f"
      },
      "source": [
        "%cd /content/Project_AI \n",
        "!git checkout ando\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Project_AI\n",
            "Checking out files: 100% (40/40), done.\n",
            "Branch 'ando' set up to track remote branch 'ando' from 'origin'.\n",
            "Switched to a new branch 'ando'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZK4KgPXC9xo",
        "outputId": "d7c7bf0d-a4d9-4efe-cef1-885aaee34b51"
      },
      "source": [
        "import sys\n",
        "DATA_PATH = \"/content/Project_AI/ando/NaverMovie/\"\n",
        "\n",
        "sys.path.append(DATA_PATH)\n",
        "train_df = pd.read_csv('Naver_MR_train.csv')\n",
        "train_input = np.load(\"Naver_MR_train_input.npy\")\n",
        "train_label = np.load(\"Naver_MR_train_label.npy\")\n",
        "test_input = np.load(\"Naver_MR_test_input.npy\")\n",
        "test_label = np.load(\"Naver_MR_test_label.npy\")\n",
        "\n",
        "prepro_configs = json.load(open(DATA_PATH + \"data_config.json\" , 'r'))\n",
        "\n",
        "train_input.shape , train_label.shape , test_input.shape , test_label.shape ,   prepro_configs['vocab_size']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((149995, 15), (149995,), (149995, 15), (149995,), 38771)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0XyuxGXQvMq"
      },
      "source": [
        "\n",
        "# CNN 모델 클래스로 정의\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class CNNClassifier(tf.keras.Model):\n",
        "\n",
        "  def __init__(self , **kargs):\n",
        "    \n",
        "    super(CNNClassifier , self).__init__(name = kargs['model_name'])\n",
        "\n",
        "    self.embedding = layers.Embedding(input_dim = kargs['vocab_size'] , output_dim = kargs['embedding_size'])\n",
        "\n",
        "    self.conv_list = [layers.Conv1D(filters = kargs['num_filters'] , kernel_size = kernel_size  , \n",
        "                                    padding = 'valid' , activation = 'relu', kernel_constraint = tf.keras.constraints.MaxNorm(max_value = 3.) )\n",
        "                                   for kernel_size in [3,4,5] ]\n",
        "\n",
        "    self.pooling  = layers.GlobalMaxPooling1D()\n",
        "    self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
        "    self.fc1 = layers.Dense(kargs['hidden_dimension'] , activation = 'relu' ,  kernel_constraint = tf.keras.constraints.MaxNorm(max_value = 3.))\n",
        "    self.fc2 = layers.Dense(kargs['ouput_dimension'] , activation = 'sigmoid' ,  kernel_constraint = tf.keras.constraints.MaxNorm(max_value = 3.))\n",
        "  \n",
        "\n",
        "  def call(self,x):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = self.dropout(x)\n",
        "    x = tf.concat([self.pooling(conv(x)) for conv in self.conv_list] , axis = 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv_jBJwjeAsw"
      },
      "source": [
        "# 신경망 생성 및 가중치 로드\n",
        "def build_Sentiment_model():\n",
        "\n",
        "  model_name = 'CNN'\n",
        "  MAX_LEN = 15\n",
        "\n",
        "  kargs = {'model_name' : model_name , 'vocab_size' : 38771 , 'embedding_size' : 256 , 'num_filters' : 150 , 'dropout_rate' : 0.5 , 'hidden_dimension': 512 ,'ouput_dimension' : 1}\n",
        "\n",
        "  model = CNNClassifier(**kargs)\n",
        "  model.compile(optimizer = tf.keras.optimizers.Adam(1e-4) , \n",
        "              loss = 'binary_crossentropy' ,\n",
        "              metrics = ['accuracy'])\n",
        "  \n",
        "  dummy_input = np.zeros((1,15))\n",
        "  dummy_label = np.zeros((1,1))\n",
        "  model.fit(dummy_input , dummy_label , batch_size= 1 , epochs = 1)\n",
        "  model.load_weights('/content/Project_AI/ando/NaverMovie/Models/CNN_2_weights.h5')\n",
        "\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYIs8KRfXcDA"
      },
      "source": [
        "\n",
        "\n",
        "class predict_Sentiment():\n",
        "  \n",
        "  def __init__(self):\n",
        "\n",
        "    self.model = build_Sentiment_model()\n",
        "\n",
        "    ## 전처리 필요한 것들 로드\n",
        "\n",
        "    # 불용어 사전\n",
        "    self.stop_words = ['은', '는' , '이' , '가' , '하', '아', '것' , '들', '의', '있' , '되' , '수' , '보' , '주' , '등' ,'한' ]\n",
        "\n",
        "    # 토크나이저 로드\n",
        "    with open('/content/Project_AI/ando/NaverMovie/tokenizer.pickle', 'rb') as handle:\n",
        "      self.tokenizer = pickle.load(handle)\n",
        "\n",
        "    # Okt 형태소 추출기 생성\n",
        "    self.okt = Okt()\n",
        "\n",
        "\n",
        "    ## 예측 신경망 생성 및 로드\n",
        "\n",
        "  # 전처리 함수\n",
        "  def preprocessing(self , text , limit_words = 15 , print_option = False ):\n",
        "\n",
        "    if print_option : print(\"원본\".ljust(15 , ' ') + \": \" , text)\n",
        "    \n",
        "    text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\" , \"\" , text)\n",
        "    if print_option : print(\"정규표현식 처리\".ljust(15 , ' ') + \": \" , text)\n",
        "\n",
        "    text = self.okt.morphs(text , stem = True)\n",
        "    if print_option : print(\"okt 형태소 추출\".ljust(15 , ' ') + \": \" , text)\n",
        "\n",
        "\n",
        "    text = [word for word in text[:limit_words]]\n",
        "    if print_option : print(\"문장 길이 조절\".ljust(15 , ' ') + \": \" , text)\n",
        "\n",
        "    text = [token for token in text if not token in self.stop_words]\n",
        "    if print_option : \n",
        "      print(\"불용어 처리\".ljust(15 , ' ') + \": \" , text)\n",
        "      print(\" \")\n",
        "      print(\" \")\n",
        "\n",
        "    return text\n",
        "\n",
        "  # 감성 예측\n",
        "  def pred_Sentiment(self , input):\n",
        "\n",
        "    print(\"입력 값 : \" , input)\n",
        "    print(\" \")\n",
        "    input = self.preprocessing(input , 15 , False)\n",
        "    input = self.tokenizer.texts_to_sequences([input])\n",
        "    input = pad_sequences(input , maxlen = 15 , padding = 'post')\n",
        "\n",
        "    pred = round(self.model.predict(input)[0][0]*100 , 2)\n",
        "    if pred >= 50 : print(\"긍정 ({} %)\".format(pred))\n",
        "    else : print(\"부정 ({} %)\".format(pred))\n",
        "    \n",
        "    return pred\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAidUN41RW7g",
        "outputId": "fdeca60e-0b02-4e34-b269-1d8ed2877be0"
      },
      "source": [
        "pred = predict_Sentiment()\n",
        "\n",
        "pred.pred_Sentiment(\"안녕하세요\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7fd61fcdb440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6849 - accuracy: 1.0000\n",
            "입력 값 :  안녕하세요\n",
            " \n",
            "원본             :  안녕하세요\n",
            "정규표현식 처리       :  안녕하세요\n",
            "okt 형태소 추출     :  ['안녕하다']\n",
            "문장 길이 조절       :  ['안녕하다']\n",
            "불용어 처리         :  ['안녕하다']\n",
            " \n",
            " \n",
            "부정 (14.85 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07paNv9gPvgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2595249f-c7bb-493c-d102-f2bd3f597753"
      },
      "source": [
        "pred.pred_Sentiment(\"이 영화 정말 재미있습니다 추천드립니다\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값 :  이 영화 정말 재미있습니다 추천드립니다\n",
            " \n",
            "원본             :  이 영화 정말 재미있습니다 추천드립니다\n",
            "정규표현식 처리       :  이 영화 정말 재미있습니다 추천드립니다\n",
            "okt 형태소 추출     :  ['이', '영화', '정말', '재미있다', '추천', '드리다']\n",
            "문장 길이 조절       :  ['이', '영화', '정말', '재미있다', '추천', '드리다']\n",
            "불용어 처리         :  ['영화', '정말', '재미있다', '추천', '드리다']\n",
            " \n",
            " \n",
            "긍정 (95.96 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95.96"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg49Bc5ffFDf",
        "outputId": "cd204875-d1b7-42f0-ba31-0d9fed32c920"
      },
      "source": [
        "pred.pred_Sentiment(\"기레기 놈들 제발 이딴 쓰레기 같은 기사 좀 쓰지마\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값 :  기레기 놈들 제발 이딴 쓰레기 같은 기사 좀 쓰지마\n",
            " \n",
            "원본             :  기레기 놈들 제발 이딴 쓰레기 같은 기사 좀 쓰지마\n",
            "정규표현식 처리       :  기레기 놈들 제발 이딴 쓰레기 같은 기사 좀 쓰지마\n",
            "okt 형태소 추출     :  ['기레기', '놈', '들', '제발', '이딴', '쓰레기', '같다', '기사', '좀', '쓰다']\n",
            "문장 길이 조절       :  ['기레기', '놈', '들', '제발', '이딴', '쓰레기', '같다', '기사', '좀', '쓰다']\n",
            "불용어 처리         :  ['기레기', '놈', '제발', '이딴', '쓰레기', '같다', '기사', '좀', '쓰다']\n",
            " \n",
            " \n",
            "부정 (0.39 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjzUCNIxfKdD",
        "outputId": "f912d12d-dbc6-41d3-8f91-f520e26e8fc9"
      },
      "source": [
        "pred.pred_Sentiment(\"뭐하냐 진짜\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값 :  뭐하냐 진짜\n",
            " \n",
            "원본             :  뭐하냐 진짜\n",
            "정규표현식 처리       :  뭐하냐 진짜\n",
            "okt 형태소 추출     :  ['뭐', '하다', '진짜']\n",
            "문장 길이 조절       :  ['뭐', '하다', '진짜']\n",
            "불용어 처리         :  ['뭐', '하다', '진짜']\n",
            " \n",
            " \n",
            "부정 (9.17 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfqbxdHBfTKj",
        "outputId": "a5be48e8-5fa6-43ff-b964-efbf81ba0277"
      },
      "source": [
        "pred.pred_Sentiment(\"와 정말 대단하신 분이네요 존경스럽습니다\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값 :  와 정말 대단하신 분이네요 존경스럽습니다\n",
            " \n",
            "원본             :  와 정말 대단하신 분이네요 존경스럽습니다\n",
            "정규표현식 처리       :  와 정말 대단하신 분이네요 존경스럽습니다\n",
            "okt 형태소 추출     :  ['오다', '정말', '대단하다', '불다', '존경', '스럽다']\n",
            "문장 길이 조절       :  ['오다', '정말', '대단하다', '불다', '존경', '스럽다']\n",
            "불용어 처리         :  ['오다', '정말', '대단하다', '불다', '존경', '스럽다']\n",
            " \n",
            " \n",
            "긍정 (87.64 %)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKa409e5PL3t",
        "outputId": "73643803-f57d-44ce-efc3-e273a7828bfc"
      },
      "source": [
        "\n",
        "Input = \"미쳤냐?????? 진짜 정신 나갔네\"\n",
        "\n",
        "pred.show_predict(Input)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 값 :  미쳤냐?????? 진짜 정신 나갔네\n",
            " \n",
            "원본             :  미쳤냐?????? 진짜 정신 나갔네\n",
            "정규표현식 처리       :  미쳤냐 진짜 정신 나갔네\n",
            "okt 형태소 추출     :  ['미치다', '진짜', '정신', '나가다']\n",
            "문장 길이 조절       :  ['미치다', '진짜', '정신', '나가다']\n",
            "불용어 처리         :  ['미치다', '진짜', '정신', '나가다']\n",
            " \n",
            " \n",
            "[[254, 16, 487, 568]]\n",
            "부정 (8.73 %)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}