{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get different url : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ando\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1020: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pokemon.fandom.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling Proceeding..\n",
      "[0] 이상해씨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ando\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1020: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ko.pokemon.wikia.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5cf13201c5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;31m# 도감 설명\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_desc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrounded_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m         \u001b[0mpk_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d5cf13201c5c>\u001b[0m in \u001b[0;36mget_desc\u001b[1;34m(rounded_all)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_desc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrounded_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mrounded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrounded_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rounded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrounded\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_html(url):\n",
    "    html = \"\"\n",
    "    resp = requests.get(url , verify = False)\n",
    "\n",
    "    if resp.status_code == 200:\n",
    "        html = resp.text\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "def get_desc(rounded_all):\n",
    "    rounded = rounded_all[2]('td', class_=\"rounded\")\n",
    "\n",
    "    if rounded == []:\n",
    "        rounded = rounded_all[4]('td', class_=\"rounded\")\n",
    "        if rounded == []:\n",
    "            rounded = rounded_all[6]('td', class_=\"rounded\")\n",
    "            if rounded == []:\n",
    "                rounded = rounded_all[8]('td', class_=\"rounded\")\n",
    "                if rounded == []:\n",
    "                    rounded = rounded_all[10]('td', class_=\"rounded\")\n",
    "                    if rounded == []:\n",
    "                        rounded = rounded_all[12]('td', class_=\"rounded\")\n",
    "\n",
    "    desc = \"\"\n",
    "    prev_d = \"\"\n",
    "    for td in rounded:\n",
    "        d = td.get_text().strip()\n",
    "        if prev_d == d or d == '':\n",
    "            continue\n",
    "        prev_d = d\n",
    "        desc += d\n",
    "    if desc == \"\":\n",
    "        print(\"Desc Null : [{}] {}\".format(i, pk_names[i]))\n",
    "\n",
    "    return desc\n",
    "\n",
    "\n",
    "def get_type(rounded_all):\n",
    "    rounded = rounded_all[0]('span', class_=\"split-cell text-white\")\n",
    "    pk_type_sub1 = ''\n",
    "    pk_type_sub2 = ''\n",
    "\n",
    "    for span in rounded:\n",
    "        if pk_type_sub1 == '':\n",
    "            pk_type_sub1 = span.get_text().strip()\n",
    "\n",
    "        else:\n",
    "            if span.get_text().strip() != '':\n",
    "                pk_type_sub2 = span.get_text().strip()\n",
    "            else:\n",
    "                pk_type_sub2 = None\n",
    "\n",
    "#     pk_type = ','.join(pk_type_sub)\n",
    "\n",
    "    return pk_type_sub1, pk_type_sub2\n",
    "\n",
    "\n",
    "\n",
    "def get_egggroup(rounded_all):\n",
    "    rounded = rounded_all[0]('td')\n",
    "    egg_group = ''\n",
    "    egg_group_sub = []\n",
    "    for td in rounded:\n",
    "        flag = False\n",
    "        for a in td('a'):\n",
    "            if flag:\n",
    "                egg_group_sub.append(a.get_text().strip())\n",
    "#                 egg_group += a.get_text().strip()\n",
    "            if a.get_text().strip() == \"알그룹\":\n",
    "                flag = True\n",
    "    egg_group = ','.join(egg_group_sub)\n",
    "    return egg_group\n",
    "\n",
    "\n",
    "\n",
    "def get_life(soup):\n",
    "    \n",
    "    for tag in soup.find_all('h2'):\n",
    "        if tag.get_text().strip() == '생태':\n",
    "            life_h2_tag = tag\n",
    "            \n",
    "    pk_life = ''\n",
    "    pk_life_sub = []\n",
    "    try:\n",
    "        for element in life_h2_tag.next_elements:\n",
    "            if element.name == 'h2':\n",
    "                break\n",
    "\n",
    "            if element.name == 'p':\n",
    "                pk_life_sub.append(element.get_text().strip())\n",
    "            elif element.name == 'li':\n",
    "                    pk_life_sub.append(element.get_text().strip())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    pk_life = ' '.join(pk_life_sub)\n",
    "    \n",
    "#     if pk_life == \"\":\n",
    "#         if '생태' in soup.find_all('meta',property=\"og:description\")[0].attrs['content']:\n",
    "#             pk_life = soup.find_all('meta',property=\"og:description\")[0].attrs['content'].split('생태')[1]\n",
    "#         else:\n",
    "#             pk_life = soup.find_all('meta',property=\"og:description\")[0].attrs['content']\n",
    "                \n",
    "    if pk_life == \"\":\n",
    "        print(\"Life Null : [{}] {}\".format(i, pk_names[i]))\n",
    "\n",
    "    return pk_life\n",
    "\n",
    "\n",
    "# 1. url 불러오기\n",
    "url_idx =1 # 전국도감 1세대 ~ 7세대까지\n",
    "url_number = 0 # file 저장용\n",
    "while url_idx < 8:\n",
    "    \n",
    "    print(\"Get different url : {}\".format(url_idx))\n",
    "    url = \"http://ko.pokemon.wikia.com/wiki/%EC%A0%84%EA%B5%AD%EB%8F%84%EA%B0%90/{}%EC%84%B8%EB%8C%80\".format(url_idx)\n",
    "    url_number = url_idx\n",
    "    \n",
    "    c = get_html(url)\n",
    "\n",
    "    # 2. url 내의 세부 링크 받아오기\n",
    "    soup = BeautifulSoup(c, \"html5lib\")\n",
    "\n",
    "    pages = []\n",
    "    table = soup.find_all(class_=\"bg-white\")\n",
    "\n",
    "    pk_names = []\n",
    "    prev_name = \"\"\n",
    "    for i in range(len(table)):\n",
    "        pk_name = table[i]('td')[3].a.get('title')\n",
    "    #     pk_name = table[i]('td')[3].a['title']\n",
    "        if prev_name == pk_name:\n",
    "            continue\n",
    "        prev_name = pk_name\n",
    "        link = table[i]('td')[3].a.get('href')\n",
    "    #     link = table[i]('td')[3].a['href']\n",
    "        link = \"http://ko.pokemon.wikia.com\" + link\n",
    "        pk_name = pk_name.split(' ')[0]\n",
    "        pk_names.append(pk_name)\n",
    "        pages.append(link)\n",
    "\n",
    "    # 3. url 내의 필요한 부분 크롤링\n",
    "    i = 0\n",
    "    pk_desc = []\n",
    "    pk_type1 = []\n",
    "    pk_type2 = []\n",
    "    egg_groups = []\n",
    "#     pk_life = []\n",
    "    print(\"Crawling Proceeding..\")\n",
    "    for page in pages:\n",
    "        print(\"[{}] {}\".format(i, pk_names[i]))\n",
    "        # page = pages[2]\n",
    "        c = get_html(page)\n",
    "        soup = BeautifulSoup(c, \"html5lib\")\n",
    "\n",
    "        rounded_all = soup.find_all(\"div\", class_=\"rounded\")\n",
    "        \n",
    "\n",
    "        # 도감 설명\n",
    "        desc = get_desc(rounded_all)\n",
    "        pk_desc.append(desc)\n",
    "\n",
    "        # 속성\n",
    "        pk_type_sub1, pk_type_sub2 = get_type(rounded_all)\n",
    "        pk_type1.append(pk_type_sub1)\n",
    "        pk_type2.append(pk_type_sub2)\n",
    "\n",
    "        # 알 그룹\n",
    "        egg_group = get_egggroup(rounded_all)\n",
    "        egg_groups.append(egg_group)\n",
    "        \n",
    "        # 생태\n",
    "#         desc = desc + \" \" +get_life(soup)\n",
    "#         pk_life.append(life)\n",
    "#         pk_desc.append(desc)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # 4. data csv로 저장\n",
    "    DATA_PATH = \"./data/\"\n",
    "\n",
    "    pk_data = pd.DataFrame()\n",
    "    pk_data['name'] = pk_names\n",
    "    pk_data['desc'] = pk_desc\n",
    "    pk_data['type1'] = pk_type1\n",
    "    pk_data['type2'] = pk_type2\n",
    "    pk_data['egg_group'] = egg_groups\n",
    "#     pk_data['life'] = pk_life\n",
    "\n",
    "    if not os.path.isdir(DATA_PATH):\n",
    "        os.mkdir(DATA_PATH)\n",
    "\n",
    "    # pk_data.to_csv(DATA_PATH + \"pk_data_g1.csv\")\n",
    "    pk_data.to_csv(DATA_PATH + \"pk_data_g{}.csv\".format(url_number), index=False, quotechar='\"', encoding='utf-8-sig', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "    url_idx += 1 # 전국도감 url 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
